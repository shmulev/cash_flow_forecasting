{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">TODO: Regression</font>\n",
    "## Sections:\n",
    "\n",
    "* [1. Feature selection](#section1)\n",
    "    * [1.1 Univariate feature selection](#section1.1)\n",
    "    * [1.2 Feature selection using fitted model](#section1.2)\n",
    "* [2. Models for regression](#section2)\n",
    "    * [2.1 Lasso and Linear SVR](#section2.1)\n",
    "    * [2.2 ARD regression](#section2.2)\n",
    "    * [2.2 Nonlinear methods](#section2.3)\n",
    "* [3. Model selection](#section3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">1. Feature selection</font> <a id=\"section1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Univariate feature selection (<a href=\"http://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection\">link</a>) <a id=\"section1.1\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150, 2)\n"
     ]
    }
   ],
   "source": [
    "#example\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression, chi2\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "print(X.shape)\n",
    "X_new = SelectKBest(f_regression, k=2).fit_transform(X, y)\n",
    "print(X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.4,  0.2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Feature selection using fitted model (<a href=\"http://scikit-learn.org/stable/modules/feature_selection.html#feature-selection-using-selectfrommodel\">link</a>) <a id=\"section1.2\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150, 2)\n"
     ]
    }
   ],
   "source": [
    "#use l1-regularized linear model for regression (Lasso) to estimate feature importance\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "print(X.shape)\n",
    "\n",
    "#without tuning alpha (regularization term parameter)\n",
    "lasso_model = Lasso(alpha=0.01, normalize=True, random_state=1234).fit(X, y)\n",
    "#with tuning alpha (regularization term parameter)\n",
    "lasso_model = LassoCV(eps=1e-6, n_alphas=100, normalize=False, cv=3, n_jobs=-1, random_state=1234, selection='random').fit(X,y)\n",
    "\n",
    "model = SelectFromModel(lasso_model, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "print(X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.4,  0.2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !NB: we can use feature selection as a part of Pipeline (<a href=\"http://scikit-learn.org/stable/modules/feature_selection.html#feature-selection-as-part-of-a-pipeline\">link</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">2. Models for regression</font> <a id=\"section2\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Lasso (<a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\">link</a>) or LinearSVC (<a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html\">link</a>) <a id=\"section2.1\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "#use l1-regularized linear model for regression (Lasso, LinearSVR) to estimate feature importance\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "print(X.shape)\n",
    "\n",
    "#without tuning alpha (regularization term parameter)\n",
    "lasso_model = Lasso(alpha=0.01, normalize=True, random_state=1234).fit(X, y)\n",
    "#with tuning alpha (regularization term parameter)\n",
    "lassoCV_model = LassoCV(eps=1e-6, n_alphas=100, normalize=False, cv=3, n_jobs=-1, random_state=1234, selection='random').fit(X,y)\n",
    "#Support Vector Machine Regressor\n",
    "svr_model = LinearSVR(epsilon=1e2, C=1e-6, max_iter=50).fit(X,y)\n",
    "\n",
    "#take model to make predictions\n",
    "models = [lasso_model, lassoCV_model, svr_model]\n",
    "y_preds = []\n",
    "for model in models:\n",
    "    y_preds.append(model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for regrission: MSE and R2-score (<a href=\"http://scikit-learn.org/stable/modules/model_evaluation.html#r2-score-the-coefficient-of-determination\">link</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso   => MSE: \t 0.0648117971182\n",
      "Lasso   => R2: \t\t 0.902782304323\n",
      "\n",
      "LassoCV => MSE: \t 0.0579932650788\n",
      "LassoCV => R2: \t\t 0.913010102382\n",
      "\n",
      "Linear SVR => MSE: \t 1.66666666667\n",
      "Linear SVR => R2: \t\t -1.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#metrics for validation of our model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "names = [\"Lasso  \", \"LassoCV\", \"Linear SVR\"]\n",
    "for y_pred, name in zip(y_preds, names):\n",
    "    print(name + ' => MSE: \\t', mean_squared_error(y, y_pred))\n",
    "    print(name + ' => R2: \\t\\t', r2_score(y, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Bayessian Automatic Relevance Determination (ARD) Regression (<a href=\"http://scikit-learn.org/stable/modules/linear_model.html#automatic-relevance-determination-ard\">link</a>) <a id=\"section2.2\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARDRegression is very similar to Bayesian Ridge Regression, but can lead to sparser weights. ARDRegression poses a different prior over w, by dropping the assumption of the Gaussian being spherical.\n",
    "Instead, the distribution over w is assumed to be an axis-parallel, elliptical Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "ARD => MSE: \t 0.0465415031752\n",
      "ARD => R2: \t 0.930187745237\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "print(X.shape)\n",
    "\n",
    "ard_model = ARDRegression(compute_score=True).fit(X,y)\n",
    "\n",
    "y_pred = ard_model.predict(X)\n",
    "print(\"ARD\" + ' => MSE: \\t', mean_squared_error(y, y_pred))\n",
    "print(\"ARD\" + ' => R2: \\t', r2_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Nonlinear methods (optional) <a id=\"section2.3\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "SVR RBF kernel => MSE: \t\t 0.0648117971182\n",
      "SVR RBF kernel => R2: \t\t 0.902782304323\n",
      "\n",
      "Random Forest => MSE: \t\t 0.0579932650788\n",
      "Random Forest => R2: \t\t 0.913010102382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "print(X.shape)\n",
    "\n",
    "svr_model = SVR(C=1e2).fit(X,y)\n",
    "rf_model = RandomForestRegressor(n_estimators=100, n_jobs=-1).fit(X,y)\n",
    "\n",
    "#take model to make predictions\n",
    "models = [lasso_model, lassoCV_model, svr_model]\n",
    "y_preds = []\n",
    "for model in models:\n",
    "    y_preds.append(model.predict(X))\n",
    "    \n",
    "    \n",
    "#metrics for validation of our model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "names = [\"SVR RBF kernel\", \"Random Forest\"]\n",
    "for y_pred, name in zip(y_preds, names):\n",
    "    print(name + ' => MSE: \\t\\t', mean_squared_error(y, y_pred))\n",
    "    print(name + ' => R2: \\t\\t', r2_score(y, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">3. Model selection</font> <a id=\"section3\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With method should be fine-tuned. We can do with using Cross-Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_pipeline(model, parameters, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
    "    gs_model = GridSearchCV(model, parameters, scoring='neg_mean_squared_error', n_jobs=-1, verbose=5)\n",
    "    gs_model.fit(X_train, y_train)\n",
    "    \n",
    "    best_regressor = gs_model.best_estimator_\n",
    "    y_pred = best_regressor.predict(X_test)\n",
    "    print('MSE: \\t', mean_squared_error(y_test, y_pred))\n",
    "    print('R2: \\t', r2_score(y_test, y_pred))\n",
    "    return best_regressor, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: \t 0.0562313527756\n",
      "R2: \t 0.902863306146\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  81 | elapsed:    3.1s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:    3.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: \t 0.0380227907457\n",
      "R2: \t 0.939000870461\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: \t 0.0570714066293\n",
      "R2: \t 0.909728882309\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: \t 0.0433080517477\n",
      "R2: \t 0.935997953082\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:    3.4s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    3.5s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: \t 0.0311031519274\n",
      "R2: \t 0.955496285\n"
     ]
    }
   ],
   "source": [
    "models = [Lasso(), LinearSVR(), ARDRegression(), SVR(), RandomForestRegressor()]\n",
    "\n",
    "parameters_lasso = {'alpha': np.logspace(-4,4,9),\n",
    "                    'selection': ['random']}\n",
    "parameters_linear_svr = {'C': np.logspace(-4,4,9),\n",
    "                         'epsilon': [1e-4,1e-3,0.]}\n",
    "parameters_adr = {'alpha_1': [1e-06,1e-5], \n",
    "                  'alpha_2': [1e-06,1e-5],\n",
    "                  'lambda_1': [1e-5,1e-06],\n",
    "                  'lambda_2': [1e-5,1e-06]}\n",
    "parameters_svr = {'C': np.logspace(-4,4,9),\n",
    "                 'kernel': ['rbf', 'sigmoid']}\n",
    "parameters_rf = {'max_depth': [1,3,5],\n",
    "                 'n_jobs': [-1]}\n",
    "params = [parameters_lasso, parameters_linear_svr, parameters_adr, parameters_svr, parameters_rf]\n",
    "\n",
    "y_preds = []\n",
    "models_ = []\n",
    "for model, param in zip(models, params):\n",
    "    model_, y_pred = training_pipeline(model, param, X, y)\n",
    "    models_.append(model_)\n",
    "    y_preds.append(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see when we tuned our models they performs almost equally well. However, for a large data sets, linear models are much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
